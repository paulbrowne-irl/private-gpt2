python ingest.py
Downloading (…)e9125/.gitattributes: 100%|█████████████████████████████████████████████████████████████████████████| 1.18k/1.18k [00:00<00:00, 7.40MB/s]
Downloading (…)_Pooling/config.json: 100%|██████████████████████████████████████████████████████████████████████████████| 190/190 [00:00<00:00, 728kB/s]
Downloading (…)7e55de9125/README.md: 100%|█████████████████████████████████████████████████████████████████████████| 10.6k/10.6k [00:00<00:00, 36.4MB/s]
Downloading (…)55de9125/config.json: 100%|█████████████████████████████████████████████████████████████████████████████| 612/612 [00:00<00:00, 3.58MB/s]
Downloading (…)ce_transformers.json: 100%|██████████████████████████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 814kB/s]
Downloading (…)125/data_config.json: 100%|█████████████████████████████████████████████████████████████████████████| 39.3k/39.3k [00:00<00:00, 6.23MB/s]
Downloading pytorch_model.bin: 100%|███████████████████████████████████████████████████████████████████████████████| 90.9M/90.9M [00:20<00:00, 4.51MB/s]
Downloading (…)nce_bert_config.json: 100%|████████████████████████████████████████████████████████████████████████████| 53.0/53.0 [00:00<00:00, 259kB/s]
Downloading (…)cial_tokens_map.json: 100%|██████████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 656kB/s]
Downloading (…)e9125/tokenizer.json: 100%|███████████████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 2.43MB/s]
Downloading (…)okenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████████| 350/350 [00:00<00:00, 2.53MB/s]
Downloading (…)9125/train_script.py: 100%|█████████████████████████████████████████████████████████████████████████| 13.2k/13.2k [00:00<00:00, 40.6MB/s]
Downloading (…)7e55de9125/vocab.txt: 100%|███████████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 5.63MB/s]
Downloading (…)5de9125/modules.json: 100%|█████████████████████████████████████████████████████████████████████████████| 349/349 [00:00<00:00, 1.74MB/s]
Creating new vectorstore
Loading documents from source_documents
Loading new documents: 100%|████████████████████| 26/26 [00:01<00:00, 16.61it/s]
Loaded 664 new documents from source_documents
Split into 3700 chunks of text (max. 500 tokens each)
Creating embeddings. May take some minutes...
Ingestion complete! You can now run privateGPT.py to query your documents